+++
bibkey = "dstc19task1"
bibtex = """@InProceedings{dstc19task1,
  title     = {DSTC7 Task 1: Noetic End-to-End Response Selection},
  author    = {Chulaka Gunasekara and Jonathan K. Kummerfeld and Lazaros Polymenakos and and Walter S. Lasecki},
  year      = {2019},
  booktitle = {7th Edition of the Dialog System Technology Challenges at AAAI 2019},
  url       = {http://workshop.colips.org/dstc7/papers/dstc7_task1_final_report.pdf},
  month     = {January},
  url       = {http://www.jkk.name/pub/ws18dstc_task1.pdf},
}
"""
title = "DSTC7 Task 1: Noetic End-to-End Response Selection"
date = "2019-01-01"
draft = false
preprint = false
authors = ["Chulaka Gunasekara", "<span style='text-decoration:underline;'>Jonathan K. Kummerfeld</span>", "Lazaros Polymenakos", "and Walter S. Lasecki"]
publication_types = ["1"]
publication = "7th Edition of the Dialog System Technology Challenges at AAAI 2019"
publication_short = "DSTC"
abstract = "Goal-oriented dialogue in complex domains is an extremely challenging problem and there are relatively few datasets. This task provided two new resources that presented different challenges: one was focused but small, while the other was large but diverse. We also considered several new variations on the next utterance selection problem: (1) increasing the number of candidates, (2) including paraphrases, and (3) not including a correct option in the candidate set. Twenty teams participated, developing a range of neural network models, including some that successfully incorporated external data to boost performance. Both datasets have been publicly released, enabling future work to build on these results, working towards robust goal-oriented dialogue systems."
abstract_short = "Goal-oriented dialogue in complex domains is an extremely challenging problem and there are relatively few datasets. This task provided two new resources that presented different challenges: one was focused but small, while the other was large but diverse. We also considered several new variations on the next utterance selection problem: (1) increasing the number of candidates, (2) including paraphrases, and (3) not including a correct option in the candidate set. Twenty teams participated, developing a range of neural network models, including some that successfully incorporated external data to boost performance. Both datasets have been publicly released, enabling future work to build on these results, working towards robust goal-oriented dialogue systems."
address = ""
doi = ""
issue = ""
number = ""
pages = ""
publisher = ""
volume = ""
math = true
highlight = false
image_preview = ""
selected = false
url_pdf = "http://www.jkk.name/pub/ws18dstc_task1.pdf"
url_poster = ""
url_interview = ""
url_arxiv = ""
url_code = ""
url_dataset = ""
url_project = ""
url_slides = ""
url_video = ""
url_blog = ""



+++