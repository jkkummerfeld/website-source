---

bibkey: lrec18amr

title: World Knowledge for Abstract Meaning Representation Parsing

date: "2018-05-01"

year: 2018

draft: false

preprint: false

archival: true

authors: 
- Charles Welch
- admin
- Song Feng
- Rada Mihalcea

publication_types: ["1"]

publication: Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)

publication_short: LREC

abstract: In this paper we explore the role played by world knowledge in semantic parsing. We look at the types of errors that currently exist in a state-of-the-art Abstract Meaning Representation (AMR) parser, and explore the problem of how to integrate world knowledge to reduce these errors. We look at three types of knowledge from (1) WordNet hypernyms and super senses, (2) Wikipedia entity links, and (3) retraining a named entity recognizer to identify concepts in AMR. The retrained entity recognizer is not perfect and cannot recognize all concepts in AMR and we examine the limitations of the named entity features using a set of oracles. The oracles show how performance increases if it can recognize different subsets of AMR concepts. These results show improvement on multiple fine-grained metrics, including a 6% increase in named entity F-score, and provide insight into the potential of world knowledge for future work in Abstract Meaning Representation parsing.

abstract_short: In this paper we explore the role played by world knowledge in semantic parsing. We look at the types of errors that currently exist in a state-of-the-art Abstract Meaning Representation (AMR) parser, and explore the problem of how to integrate world knowledge to reduce these errors. We look at three types of knowledge from (1) WordNet hypernyms and super senses, (2) Wikipedia entity links, and (3) retraining a named entity recognizer to identify concepts in AMR. The retrained entity recognizer is not perfect and cannot recognize all concepts in AMR and we examine the limitations of the named entity features using a set of oracles. The oracles show how performance increases if it can recognize different subsets of AMR concepts. These results show improvement on multiple fine-grained metrics, including a 6% increase in named entity F-score, and provide insight into the potential of world knowledge for future work in Abstract Meaning Representation parsing.

address: 

doi: 

issue: 

number: 

pages: 

publisher: 

volume: 

math: true

highlight: false

image_preview: 

selected: false

url_pdf: "http://www.lrec-conf.org/proceedings/lrec2018/pdf/1085.pdf"

url_poster: 

url_interview: 

url_arxiv: 

url_code: 

url_dataset: 

url_project: 

url_slides: 

url_video: 

url_blog: 

links: 

citation_count: 1
citations:
- title: Towards Turkish Abstract Meaning Representation
  year: 2019
  url: "https://www.aclweb.org/anthology/P19-2006.pdf"
  venue: "ACL: SRW"
  authors: Zahra Azin, Gulcsen Eryigit


---