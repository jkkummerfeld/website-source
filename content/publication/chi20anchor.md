+++
bibkey = "chi20anchor"
bibtex = """@InProceedings{chi20anchor,
  author    = {Jordan S. Huffaker and Jonathan K. Kummerfeld and Walter S. Lasecki and Mark S. Ackerman},
  title     = {Crowdsourced Detection of Emotionally Manipulative Language},
  year      = {2020},
  publisher = {Association for Computing Machinery},
  booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  location  = {Honolulu, Hawaii},
  url       = {http://www.jkk.name/pub/chi20anchor.pdf},
}
"""
title = "Crowdsourced Detection of Emotionally Manipulative Language"
date = "2020-01-01"
draft = false
preprint = false
archival = true
authors = ["Jordan S. Huffaker", "<span style='text-decoration:underline;'>Jonathan K. Kummerfeld</span>", "Walter S. Lasecki", "Mark S. Ackerman"]
publication_types = ["1"]
publication = "Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems"
publication_short = "CHI"
abstract = "Detecting rhetoric that manipulates readers’ emotions requires distinguishing intrinsically emotional content (IEC; e.g., a parent losing a child) from emotionally manipulative language (EML; e.g., using fear-inducing language to spread anti-vaccine propaganda). However, this remains an open classifcation challenge for both automatic and crowdsourcing approaches. Machine Learning approaches only work in narrow domains where labeled training data is available, and non-expert annotators tend to confate IEC with EML. We introduce an approach, anchor comparison, that leverages workers’ ability to identify and remove instances of EML in text to create a paraphrased 'anchor text', which is then used as a comparison point to classify EML in the original content. We evaluate our approach with a dataset of news-style text snippets and show that precision and recall can be tuned for system builders’ needs. Our contribution is a crowdsourcing approach that enables non-expert disentanglement of social references from content."
abstract_short = "Detecting rhetoric that manipulates readers’ emotions requires distinguishing intrinsically emotional content (IEC; e.g., a parent losing a child) from emotionally manipulative language (EML; e.g., using fear-inducing language to spread anti-vaccine propaganda). However, this remains an open classifcation challenge for both automatic and crowdsourcing approaches. Machine Learning approaches only work in narrow domains where labeled training data is available, and non-expert annotators tend to confate IEC with EML. We introduce an approach, anchor comparison, that leverages workers’ ability to identify and remove instances of EML in text to create a paraphrased 'anchor text', which is then used as a comparison point to classify EML in the original content. We evaluate our approach with a dataset of news-style text snippets and show that precision and recall can be tuned for system builders’ needs. Our contribution is a crowdsourcing approach that enables non-expert disentanglement of social references from content."
address = ""
doi = ""
issue = ""
number = ""
pages = ""
publisher = "Association for Computing Machinery"
volume = ""
math = true
highlight = false
image_preview = ""
selected = false
url_pdf = "http://www.jkk.name/pub/chi20anchor.pdf"
url_poster = ""
url_interview = ""
url_arxiv = ""
url_code = ""
url_dataset = ""
url_project = ""
url_slides = ""
url_video = ""
url_blog = ""



+++