---

bibkey: emnlp20taboo

title: Iterative Feature Mining for Constraint-Based Data Collection to Increase Data Diversity and Model Robustness

date: "2020-11-01"

year: 2020

draft: false

preprint: false

archival: true

authors: 
- Stefan Larson
- Anthony Zheng
- Anish Mahendran
- Rishi Tekriwal
- Adrian Cheung
- Eric Guldan
- Kevin Leach
- admin

publication_types: ["1"]

publication: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)

publication_short: EMNLP (short)

abstract: Diverse data is crucial for training robust models, but crowdsourced text often lacks diversity as workers tend to write simple variations from prompts. We propose a general approach for guiding workers to write more diverse text by iteratively constraining their writing. We show how prior workflows are special cases of our approach, and present a way to apply the approach to dialog tasks such as intent classification and slot-filling. Using our method, we create more challenging versions of test sets from prior dialog datasets and find dramatic performance drops for standard models. Finally, we show that our approach is complementary to recent work on improving data diversity, and training on data collected with our approach leads to more robust models.

abstract_short: Diverse data is crucial for training robust models, but crowdsourced text often lacks diversity as workers tend to write simple variations from prompts. We propose a general approach for guiding workers to write more diverse text by iteratively constraining their writing. We show how prior workflows are special cases of our approach, and present a way to apply the approach to dialog tasks such as intent classification and slot-filling. Using our method, we create more challenging versions of test sets from prior dialog datasets and find dramatic performance drops for standard models. Finally, we show that our approach is complementary to recent work on improving data diversity, and training on data collected with our approach leads to more robust models.

address: 

doi: 10.18653/v1/2020.emnlp-main.650

issue: 

number: 

pages: 8097--8106

publisher: 

volume: 

math: true

highlight: false

image_preview: 

selected: false

url_pdf: "https://www.aclweb.org/anthology/2020.emnlp-main.650"

url_poster: 

url_interview: 

url_arxiv: 

url_code: 

url_dataset: 

url_project: 

url_slides: 

url_video: 

url_blog: /post/2020-10-10_taboo/

links: 

citation_count: 0
citations:


---