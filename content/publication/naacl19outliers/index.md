---

bibkey: naacl19outliers

title: Outlier Detection for Improved Data Quality and Diversity in Dialog Systems

date: "2019-06-01"

year: 2019

draft: false

preprint: false

archival: true

authors: 
- Stefan Larson
- Anish Mahendran
- Andrew Lee
- admin
- Parker Hill
- Michael Laurenzano
- Johann Hauswald
- Lingjia Tang
- Jason Mars

publication_types: ["1"]

publication: "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)"

publication_short: NAACL

abstract: "In a corpus of data, outliers are either errors: mistakes in the data that are counterproductive, or are unique: informative samples that improve model robustness. Identifying outliers can lead to better datasets by (1) removing noise in datasets and (2) guiding collection of additional data to fill gaps. However, the problem of detecting both outlier types has received relatively little attention in NLP, particularly for dialog systems. We introduce a simple and effective technique for detecting both erroneous and unique samples in a corpus of short texts using neural sentence embeddings combined with distance-based outlier detection. We also present a novel data collection pipeline built atop our detection technique to automatically and iteratively mine unique data samples while discarding erroneous samples. Experiments show that our outlier detection technique is effective at finding errors while our data collection pipeline yields highly diverse corpora that in turn produce more robust intent classification and slot-filling models."

abstract_short: "In a corpus of data, outliers are either errors: mistakes in the data that are counterproductive, or are unique: informative samples that improve model robustness. Identifying outliers can lead to better datasets by (1) removing noise in datasets and (2) guiding collection of additional data to fill gaps. However, the problem of detecting both outlier types has received relatively little attention in NLP, particularly for dialog systems. We introduce a simple and effective technique for detecting both erroneous and unique samples in a corpus of short texts using neural sentence embeddings combined with distance-based outlier detection. We also present a novel data collection pipeline built atop our detection technique to automatically and iteratively mine unique data samples while discarding erroneous samples. Experiments show that our outlier detection technique is effective at finding errors while our data collection pipeline yields highly diverse corpora that in turn produce more robust intent classification and slot-filling models."

address: 

doi: 

issue: 

number: 

pages: 517--527

publisher: 

volume: 

math: true

highlight: false

image_preview: 

selected: false

url_pdf: "https://www.aclweb.org/anthology/N19-1051.pdf"

url_poster: 

url_interview: 

url_arxiv: "https://arxiv.org/abs/1904.03122"

url_code: 

url_dataset: "https://github.com/clinc/uniqueness"

url_project: 

url_slides: 

url_video: 

url_blog: 

links: 
- name: ArXiv
  url: https://arxiv.org/abs/1904.03122

citation_count: 3
citations:
- title: "User Utterance Acquisition for Training Task-Oriented Bots: A Review of Challenges, Techniques and Opportunities"
  year: 2020
  url: 
  venue: IEEE Internet Computing
  authors: Mohammad-Ali Yaghoub-Zadeh-Fard, Boualem Benatallah, Fabio Casati, Moshe Chai Barukh, Shayan Zamanirad
- title: Treating Dialogue Quality Evaluation as an Anomaly Detection Problem
  year: 2020
  url: 
  venue: LREC
  authors: Rostislav Nedelchev, Ricardo Usbeck and Jens Lehmann
- title: More Diverse Dialogue Datasets via Diversity-Informed Data Collection
  year: 2020
  url: 
  venue: ACL
  authors: Katherine Stasaski, Grace Hui Yang, and Marti A. Hearst


---