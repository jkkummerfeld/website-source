---

bibkey: alta09tagging

title: Faster parsing and supertagging model estimation

date: "2009-12-01"

year: 2009

draft: false

preprint: false

archival: true

authors: 
- admin
- Jessika Roesner
- James R. Curran

publication_types: ["1"]

publication: Proceedings of the Australasian Language Technology Association Workshop 2009

publication_short: ALTA

abstract: Parsers are often the bottleneck for data acquisition, processing text too slowly to be widely applied. One way to improve the efficiency of parsers is to construct more confident statistical models. More training data would enable the use of more sophisticated features and also provide more evidence for current features, but gold standard annotated data is limited and expensive to produce.\n\nWe demonstrate faster methods for training a supertagger using hundreds of millions of automatically annotated words, constructing statistical models that further constrain the number of derivations the parser must consider. By introducing new features and using an automatically annotated corpus we are able to double parsing speed on Wikipedia and the Wall Street Journal, and gain accuracy slightly when parsing Section 00 of the Wall Street Journal.

abstract_short: Parsers are often the bottleneck for data acquisition, processing text too slowly to be widely applied. One way to improve the efficiency of parsers is to construct more confident statistical models. More training data would enable the use of more sophisticated features and also provide more evidence for current features, but gold standard annotated data is limited and expensive to produce.\n\nWe demonstrate faster methods for training a supertagger using hundreds of millions of automatically annotated words, constructing statistical models that further constrain the number of derivations the parser must consider. By introducing new features and using an automatically annotated corpus we are able to double parsing speed on Wikipedia and the Wall Street Journal, and gain accuracy slightly when parsing Section 00 of the Wall Street Journal.

address: 

doi: 

issue: 

number: 

pages: 62--70

publisher: 

volume: 

math: true

highlight: false

image_preview: 

selected: false

url_pdf: "http://www.aclweb.org/anthology/U09-1009.pdf"

url_poster: 

url_interview: 

url_arxiv: 

url_code: 

url_dataset: 

url_project: 

url_slides: 

url_video: 

url_blog: 

links: 
- name: PDF Slides
  url: https://www.jkk.name/pub/alta09tagging_slides.pdf

citation_count: 0
citations:


---