+++
bibkey = "alta09tagging"
bibtex = """@InProceedings{alta09tagging,
  title     = {Faster parsing and supertagging model estimation},
  author    = {Jonathan K. Kummerfeld and Jessika Roesner and James R. Curran},
  booktitle = {Proceedings of the Australasian Language Technology Association Workshop 2009},
  year      = {2009},
  pages     = {62--70},
  location  = {Sydney, Australia},
  month     = {December},
  url       = {http://www.aclweb.org/anthology/U09-1009.pdf},
  slidespdf = {http://www.jkk.name/pub/alta09tagging_slides.pdf},

We demonstrate faster methods for training a supertagger using hundreds of millions of automatically annotated words, constructing statistical models that further constrain the number of derivations the parser must consider. By introducing new features and using an automatically annotated corpus we are able to double parsing speed on Wikipedia and the Wall Street Journal, and gain accuracy slightly when parsing Section 00 of the Wall Street Journal.},
}
"""
title = "Faster parsing and supertagging model estimation"
date = "2009-12-01"
draft = false
preprint = false
authors = ["<span style='text-decoration:underline;'>Jonathan K. Kummerfeld</span>", "Jessika Roesner", "James R. Curran"]
publication_types = ["1"]
publication = "Proceedings of the Australasian Language Technology Association Workshop 2009"
publication_short = "ALTA"
abstract = """Parsers are often the bottleneck for data acquisition, processing text too slowly to be widely applied. One way to improve the efficiency of parsers is to construct more confident statistical models. More training data would enable the use of more sophisticated features and also provide more evidence for current features, but gold standard annotated data is limited and expensive to produce.

We demonstrate faster methods for training a supertagger using hundreds of millions of automatically annotated words, constructing statistical models that further constrain the number of derivations the parser must consider. By introducing new features and using an automatically annotated corpus we are able to double parsing speed on Wikipedia and the Wall Street Journal, and gain accuracy slightly when parsing Section 00 of the Wall Street Journal."""
abstract_short = """Parsers are often the bottleneck for data acquisition, processing text too slowly to be widely applied. One way to improve the efficiency of parsers is to construct more confident statistical models. More training data would enable the use of more sophisticated features and also provide more evidence for current features, but gold standard annotated data is limited and expensive to produce.

We demonstrate faster methods for training a supertagger using hundreds of millions of automatically annotated words, constructing statistical models that further constrain the number of derivations the parser must consider. By introducing new features and using an automatically annotated corpus we are able to double parsing speed on Wikipedia and the Wall Street Journal, and gain accuracy slightly when parsing Section 00 of the Wall Street Journal."""
address = ""
doi = ""
issue = ""
number = ""
pages = "62--70"
publisher = ""
volume = ""
math = true
highlight = false
image_preview = ""
selected = false
url_pdf = "http://www.aclweb.org/anthology/U09-1009.pdf"
url_poster = ""
url_interview = ""
url_arxiv = ""
url_code = ""
url_dataset = ""
url_project = ""
url_slides = ""
url_video = ""
url_blog = ""
url_slides_pdf = "http://www.jkk.name/pub/alta09tagging_slides.pdf"



+++