+++
bibkey = "report09jhu"
bibtex = """@TechReport{report09jhu,
  title     = {Large-Scale Syntactic Processing: Parsing the Web},
  author    = {Stephen Clark and Ann Copestake and James R. Curran and Yue Zhang and Aurelie Herbelot and James Haggerty and Byung-Gyu Ahn and Curt Van Wyk and Jessika Roesner and Jonathan Kummerfeld and Tim Dawborn},
  year      = {2009},
  institution = {Johns Hopkins University},
  url       = {http://www.jkk.name/pub/report09jhu.pdf},
  abstract  = {Scalable syntactic processing will underpin the sophisticated language technology needed for next generation information access. Companies are already using nlp tools to create web-scale question answering and "semantic search" engines. Massive amounts of parsed web data will also allow the automatic creation of semantic knowledge resources on an unprecedented scale. The web is a challenging arena for syntactic parsing, because of its scale and variety of styles, genres, and domains.

The goals of our workshop were to scale and adapt an existing wide-coverage parser to Wikipedia text; improve the efficiency of the parser through various methods of chart pruning; use self-training to improve the efficiency and accuracy of the parser; use the parsed wiki data for an innovative form of bootstrapping to make the parser both more efficient and more accurate; and finally use the parsed web data for improved disambiguation of coordination structures, using a variety of syntactic and semantic knowledge sources.

The focus of the research was the C&C parser (Clark and Curran, 2007c), a state-of-the-art statistical parser based on Combinatory Categorial Grammar (ccg). The parser has been evaluated on a number of standard test sets achieving state-of-the-art accuracies. It has also recently been adapted successfully to the biomedical domain (Rimell and Clark, 2009). The parser is surprisingly efficient, given its detailed output, processing tens of sentences per second. For web-scale text processing, we aimed to make the parser an order of magnitude faster still. The C&C parser is one of only very few parsers currently available which has the potential to produce detailed, accurate analyses at the scale we were considering.},
}
"""
title = "Large-Scale Syntactic Processing: Parsing the Web"
date = "2009-01-01"
draft = false
preprint = false
authors = ["Stephen Clark", "Ann Copestake", "James R. Curran", "Yue Zhang", "Aurelie Herbelot", "James Haggerty", "Byung-Gyu Ahn", "Curt Van Wyk", "Jessika Roesner", "Jonathan Kummerfeld", "Tim Dawborn"]
publication_types = ["4"]
publication = "Johns Hopkins University"
publication_short = "Johns Hopkins University"
abstract = """Scalable syntactic processing will underpin the sophisticated language technology needed for next generation information access. Companies are already using nlp tools to create web-scale question answering and \"semantic search\" engines. Massive amounts of parsed web data will also allow the automatic creation of semantic knowledge resources on an unprecedented scale. The web is a challenging arena for syntactic parsing, because of its scale and variety of styles, genres, and domains.

The goals of our workshop were to scale and adapt an existing wide-coverage parser to Wikipedia text; improve the efficiency of the parser through various methods of chart pruning; use self-training to improve the efficiency and accuracy of the parser; use the parsed wiki data for an innovative form of bootstrapping to make the parser both more efficient and more accurate; and finally use the parsed web data for improved disambiguation of coordination structures, using a variety of syntactic and semantic knowledge sources.

The focus of the research was the C&C parser (Clark and Curran, 2007c), a state-of-the-art statistical parser based on Combinatory Categorial Grammar (ccg). The parser has been evaluated on a number of standard test sets achieving state-of-the-art accuracies. It has also recently been adapted successfully to the biomedical domain (Rimell and Clark, 2009). The parser is surprisingly efficient, given its detailed output, processing tens of sentences per second. For web-scale text processing, we aimed to make the parser an order of magnitude faster still. The C&C parser is one of only very few parsers currently available which has the potential to produce detailed, accurate analyses at the scale we were considering."""
abstract_short = """Scalable syntactic processing will underpin the sophisticated language technology needed for next generation information access. Companies are already using nlp tools to create web-scale question answering and \"semantic search\" engines. Massive amounts of parsed web data will also allow the automatic creation of semantic knowledge resources on an unprecedented scale. The web is a challenging arena for syntactic parsing, because of its scale and variety of styles, genres, and domains.

The goals of our workshop were to scale and adapt an existing wide-coverage parser to Wikipedia text; improve the efficiency of the parser through various methods of chart pruning; use self-training to improve the efficiency and accuracy of the parser; use the parsed wiki data for an innovative form of bootstrapping to make the parser both more efficient and more accurate; and finally use the parsed web data for improved disambiguation of coordination structures, using a variety of syntactic and semantic knowledge sources.

The focus of the research was the C&C parser (Clark and Curran, 2007c), a state-of-the-art statistical parser based on Combinatory Categorial Grammar (ccg). The parser has been evaluated on a number of standard test sets achieving state-of-the-art accuracies. It has also recently been adapted successfully to the biomedical domain (Rimell and Clark, 2009). The parser is surprisingly efficient, given its detailed output, processing tens of sentences per second. For web-scale text processing, we aimed to make the parser an order of magnitude faster still. The C&C parser is one of only very few parsers currently available which has the potential to produce detailed, accurate analyses at the scale we were considering."""
address = ""
doi = ""
issue = ""
number = ""
pages = ""
publisher = ""
volume = ""
math = true
highlight = false
image_preview = ""
selected = false
url_pdf = "http://www.jkk.name/pub/report09jhu.pdf"
url_poster = ""
url_interview = ""
url_code = ""
url_dataset = ""
url_project = ""
url_slides = ""
url_video = ""

[[citation]]
title = "Introducing More Features to Improve Chinese Shift-Reduce Parsing"
year = "2011"
url = ""
venue = "Asia Pacific Signal and Information Processing Association, Annual Summit and Conference"
author = "Hongxian Wang, Qiang Zhou, Liou Chen"

[[citation]]
title = "Probabilistic models of similarity in syntactic context"
year = "2011"
url = ""
venue = "EMNLP"
author = "Diarmuid Seaghdha, Anna Korhonen"

[[citation]]
title = "Evaluation Reportof the third Chinese Parsing Evaluation: CIPSSIGHAN-ParsEval-2012"
year = "2012"
url = ""
venue = "Proceedings of the Second CIPS-SIGHAN Joint Conference on Chinese Language Processing"
author = "Qiang Zhou"

[[citation]]
title = "Evaluation Reportof the third Chinese Parsing Evaluation: CIPSSIGHAN-ParsEval-2014"
year = "2014"
url = ""
venue = "Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing"
author = "Qiang Zhou"

[[citation]]
title = "Interpreting compound nouns with kernel methods"
year = "2013"
url = ""
venue = "Natural Language Engineering"
author = "Diarmuid Seaghdha, Ann Copestake"

[[citation]]
title = "CYK-based Decision and Forest Parsing Algorithm for Combinatory Categorial Grammar"
year = "2014"
url = ""
venue = "Journal of Information and Computational Science"
author = "Qingjiang Wang, Zhengping Wang, Lin Zhang"

[[citation]]
title = "A Streaming Dataflow Implementation of Parallel Cocke–Younger–Kasami Parser"
year = "2016"
url = ""
author = "D. Bojic, M. Bojovic"

[[citation]]
title = "Leveraging a Semantically Annotated Corpus to Disambiguate Prepositional Phrase Attachment"
year = "2015"
url = ""
venue = "Proceedings of the 11th International Conference on Computational Semantics"
author = "Guy Emerson, Ann Copestake"

[[citation]]
title = "How important is syntactic parsing accuracy? An empirical evaluation on rule-based sentiment analysis"
year = "2017"
url = "https://doi.org/10.1007/s10462-017-9584-0"
venue = "Artificial Intelligence Review"
author = "Carlos Gomez-Rodriguez, Iago Alonso-Alonso, David Vilares"


+++